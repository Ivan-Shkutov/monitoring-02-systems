## Домашнее задание к занятию "13.Системы мониторинга"

## Шкутов Иван Владимирович

### Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

### Ответ:

Минимальный набор метрик:

Инфраструктура: Загрузка CPU, свободное место на диске, Load Average.

Приложение: Доступность (HTTP), время ответа (p95, p99), количество ошибок 5xx.

Бизнес: Количество успешно сгенерированных отчетов, время их создания.

Почему:

Метрики закрывают все ключевые уязвимости проекта: CPU (тяжелые вычисления), диск (хранение отчетов), доступность (HTTP-сервис) и качество (скорость и успешность основной функции). Этот набор позволяет быстро найти причину проблем: например, рост времени ответа из-за нехватки CPU или места на диске.


2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

### Ответ:

Предлагаю перейти на SLO (цели уровня обслуживания) — это метрики обязательств перед клиентами:

Доступность сервиса: "Сервис доступен >99,5% времени".

Скорость отчётов: "95% отчётов создаются быстрее 30 секунд".

Успешность операций: ">99% запросов выполняются без ошибок".

Запас ресурсов: "Ёмкость для отчётов свободна >20%" (вместо метрик диска).

Итог: вместо графиков CPU/RAM — дашборд с этими 4 показателями и статусом "Зеленый" (все цели выполняются) или "Красный" (нарушены обязательства). Это понятный язык качества обслуживания.


3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

### Ответ:

Внедрить Sentry (или аналог — Rollbar, Bugsnag).

Почему:

Бесплатно: у них есть бесплатные тарифы.

Для разработчиков: даёт именно стек-трейсы ошибок, группировку, алерты — то, что нужно.

Без инфраструктуры: не требует развёртывания серверов. Разработчики только добавляют в код маленький SDK.

Альтернатива (если нельзя SaaS): настроить сбор stderr приложений в Loki + Grafana (бесплатный стек). Но это потребует времени на поддержку.


4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
  
### Ответ:

Формула неверная. SLA 99% считает только ошибки сервера (5xx). Вы считаете все не-2xx, включая редиректы (3xx) и клиентские ошибки (4xx).

Правильная формула:

        text
        SLA = (все_запросы − 5xx) / все_запросы

Низкий процент (70%) вызван обилием 3xx/4xx, которые в SLA не учитываются.

5. Опишите основные плюсы и минусы pull и push систем мониторинга.

### Ответ:

Push-модель (Агент сам отправляет метрики)

Плюсы:

- Проще для инициирования изнутри сети: Агент знает свой адрес и просто отправляет данные на известный адрес collector'а. Легко настроить, особенно в облаках и контейнерах.

- Гибкость отправки: Можно отправлять метрики событийно или с произвольной частотой.

- Лучше для кратковременных задач (short-lived jobs): Задача запускается, отправляет свои метрики и завершается. Центральный сервер может о ней не знать заранее.

- Естественен для отправки логов (Log-forwarding).

Минусы:

- Сложнее контролировать на стороне collector'а: Collector должен быть готов принимать данные от любого источника, что усложняет управление подписками, аутентификацию и контроль перегрузки.

- Риск потери данных: При недоступности collector'а агент может потерять метрики (буферизовать или выбросить).

- Точка сбора — единая точка отказа: Все агенты шлют в один(и) адрес.

Примеры: StatsD, Graphite, Telegraf (чаще), Loki (по умолчанию), OpenTelemetry Collector (часто как push).

Pull-модель (Центральный сервер сам "вытягивает" метрики у агентов)

Плюсы:

- Централизованный контроль: Сервер решает, когда, у кого и как часто забирать метрики. Легко добавить/удалить цель мониторинга в одной конфигурации.

- Безопасность и ACL: Сервер "ходит" внутрь сетей, можно не открывать входящие порты на каждом агенте.

- Проще детектировать недоступность: Если сервер не может подключиться к агенту — это сразу инцидент.

- Гарантия консистентности данных: Сервер получает данные на момент запроса, что важно для алертинга.

Минусы:

- Сложнее для динамических сред: Нужен механизм service discovery, чтобы узнавать о новых целях.

- Проблема с кратковременными задачами: Если задача завершилась до того, как сервер до неё "дотянулся", метрики могут быть потеряны.

- Сетевые ограничения: Сервер должен иметь сетевой доступ до каждого агента.

Примеры: Prometheus (классический pull), Blackbox Exporter.

Гибридный подход (Push + Pull Gateway)

- Для решения проблемы кратковременных задач в pull-системах используют Push Gateway (промежуточный буфер). Агент push'ует метрики в Gateway, а Prometheus pull'ит их уже оттуда.

Итог:

Pull — эталон для метрик, идеален для надежного, контролируемого сбора с долгоживущих сервисов (Prometheus).

Push — удобен для событий, логов, черной магии, динамических окружений или когда инициация соединения изнутри — must-have.

6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

        Prometheus
        TICK
        Zabbix
        VictoriaMetrics
        Nagios

### Ответ:

Pull: Prometheus, VictoriaMetrics (как drop-in замена Prometheus), Nagios (классический pull через плагины).

Push: TICK-стек (Telegraf — агент push'ует в InfluxDB).

Гибридные: Zabbix (агенты по умолчанию push'ят, но есть активные checks — pull, и возможность passive/active). VictoriaMetrics также поддерживает push через совместимый API.


7. Склонируйте себе репозиторий и запустите TICK-стэк, используя технологии docker и docker-compose.
   
В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (http://localhost:8888).

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим Z, например ./data:/var/lib:Z

![1](https://github.com/Ivan-Shkutov/monitoring-02-systems/blob/main/1.png)

![2](https://github.com/Ivan-Shkutov/monitoring-02-systems/blob/main/2.png)

![3](https://github.com/Ivan-Shkutov/monitoring-02-systems/blob/main/3.png)



8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.

   1. Нажмите на кнопку Add a query
      
   2. Изучите вывод интерфейса и выберите БД telegraf.autogen
      
   3. В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.

   4. Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

![4](https://github.com/Ivan-Shkutov/monitoring-02-systems/blob/main/4.png)



9. Изучите список telegraf inputs. Добавьте в конфигурацию telegraf следующий плагин - docker:

        [[inputs.docker]]
          endpoint = "unix:///var/run/docker.sock"

Дополнительно вам может потребоваться донастройка контейнера telegraf в docker-compose.yml дополнительного volume и режима privileged:

    telegraf:
      image: telegraf:1.4.0
      privileged: true
      volumes:
        - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
        - /var/run/docker.sock:/var/run/docker.sock:Z
      links:
        - influxdb
      ports:
        - "8092:8092/udp"
        - "8094:8094"
        - "8125:8125/udp"

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список measurments в веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

![5](https://github.com/Ivan-Shkutov/monitoring-02-systems/blob/main/5.png)

![6](https://github.com/Ivan-Shkutov/monitoring-02-systems/blob/main/6.png)



